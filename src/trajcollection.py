# for python2
#####
# This is a rewrite of original container class written by Alex.
# The idea behind this class is to serve as a data container for multiple trajectories 
# and impliment methods that aid in processing of multiple trajectories in parallel using mpi4py  
#
####
# Built-in modules
import ctypes
from itertools import chain, izip

# External modules
import numpy as np
from mpi4py import MPI 
import gp_grompy
import parallelclusterer

# Package classes
import trajectory_reader


# Type declarations.
# Need to match size of Gromacs' c_real. Which for now is 32-bit.
NumpyFloat = np.float32
CtypesFloat = ctypes.c_float
CtypesFloatPtr = ctypes.POINTER(ctypes.c_float)
MPIFloat = MPI.FLOAT


class Trajcollection():
    """
    A class to facilitate handling of strided trajectory data.
    For distributed programs (using mpi4py).

    Features:
    - Allows indexing frames by a globalID.
    - Methods for sending over mpi4py (can be used with parallel.py).

    GlobalID Conversion:
    - Is generated from only the stride length and the trajectory lengths.
    - The globalID/localID conversion is implemented by a mapping and may therefore be arbitrary.
    - This is done for simplicity/flexibility but at the cost of efficiency
      (mostly that it takes up more memory than computing it).
    """

    # ================================================================
    # Methods for Instantiation

    def __init__(self,globalIDs = None, localIDs = None, array = None):
        """
        The basic instantiator.
        It instantiates all the fields of the object (only to have them all declared in a single place).
        No other instantiator (or method) should instantiate any new fields.
        
        Parameters: globalIDs: 
        
        
        """
        self.globalIDs = globalIDs # A map from localIDs (array indices) to globalIDs :: numpy.ndarray(np.int32)
        self.localIDs  = localIDs # A map from globalIDs to localIDs (array indices) :: Python Dict

        self.array = array # :: numpy.ndarray, type is generated by the trajectory reader (unknown to me).
        
        if array is None:
            self.shape = None # :: Tuple of Integers.
            self.number_frames = None # :: Integer
            self.number_atoms  = None # :: Integer
        else:
            self.shape = array.shape # :: Tuple of Integers.
            self.number_frames = array.shape[0] # :: Integer
            self.number_atoms  = array.shape[1] # :: Integer
            

    @classmethod
    def from_files(cls, stride, trajectory_type,
                    trajectory_globalID_offsets, trajectory_filepath_list, trajectory_length_list):
        """
        Public Instantiator. (the only one)
        Instantiate by providing a list of paths to trajectory files,
        a list of the lengths of those trajectories,
        and a list of their globalID offsets (the desired globalID of the first frame of the trajectory)
        and other metadata (stride, trajectory type).
        
        A trajectory reader will be used to load the trajectories,
        loading only every n'th frame, where n = stride, starting with the first.

        Each loaded frame will be labelled with a globalID.


        Expected Types:
        stride                      :: Integer
        trajectory_type             :: String
        trajectory_globalID_offsets :: [Integer]
        trajectory_filepath_list    :: [String]
        trajectory_length_list      :: [Integer]
        """
        new = cls()
        # Hard to debug
        
        new.globalIDs = np.array(list(chain( *(  xrange(offset, length+offset, stride) 
                                        for offset, length
                                        in izip(trajectory_globalID_offsets, trajectory_length_list) 
                                    ))), dtype=np.int32)

        new.localIDs  = dict(( (globalID, localID) for localID, globalID in enumerate(new.globalIDs) ))
        # Read, concatenate trajectories.
        trajectory_coordinate_arrays = []
        for traj_filepath, traj_length in izip(trajectory_filepath_list,
                                                trajectory_length_list):
            
            traj=trajectory_reader.read_coordinates(trajectory_type, 
                                                    traj_filepath, 
                                                    traj_length, stride)
            
            trajectory_coordinate_arrays.append(traj)
         
#         trajectory_coordinate_arrays = [
#             trajectory_reader.read_coordinates(trajectory_type, traj_filepath, traj_length, stride) for 
#             (traj_filepath, traj_length) in izip(trajectory_filepath_list, trajectory_length_list)  ]

        new.array = np.concatenate(trajectory_coordinate_arrays) # np.concatenate vs np.vstack?
        new.shape = new.array.shape # Used by mpi_recv methods.
        new.number_frames = new.shape[0]
        new.number_atoms = new.shape[1]
        
        if (new.globalIDs.shape[0] != new.number_frames):
            print "[Error] Number of Frame Expected [%d] and number of frame read [%d] do not match"%(
                                                                        new.globalIDs.shape[0],new.number_frames)
            raise SystemExit("Exiting..")

        return new



    # ================================================================
    # Copy/Slicing Stuff

    def copy(self):

        new = Container()
        new._copy(self)

        new.globalIDs = np.array(self.globalIDs, dtype=np.int32)
        new.localIDs = dict(self.localIDs)
        new.array = np.array(self.array, dtype=NumpyFloat)

        return new


    def _copy(self, old): # could use a better name.
        """
        Notes:
        The objects of this Container class are intended to have unique data,
        that is, they do not share any data.

        Then, when copying, one must be sure to create new versions of data that are copied by reference.
        Such copying of data is not performed in this method.
        Objects copied by reference are marked with ***'s.
        """

        # Copy.
        self.globalIDs      = old.globalIDs     # numpy.ndarray(np.int32) - by reference. ***
        self.localIDs       = old.localIDs      # Python Dict - by reference. ***

        self.array          = old.array         # numpy.ndarray - by reference. ***
        self.shape          = old.shape         # Tuple of Integers - by value.

        self.number_frames  = old.number_frames # Integer: by value.
        self.number_atoms   = old.number_atoms  # Integer: by value.
        

    # ================================================================
    # MPI Methods: To facilitate sending containers over mpi4py.
    """
    Split the container into its array and the rest of its data (the metadata),
    in order to send the array as a buffer (bypassing pickling).
    """
    def _mpi_split(self):
        """ Note: there is no need to remove references to globalID and localID
            since the other node recieves a copy of these objects.
        """
        metadata_part = Container()
        metadata_part._copy(self)
        metadata_part.array = None

        array_part = self.array

        return metadata_part, array_part


    def mpi_send(self, comm, dest_rank):

        metadata_part, array_part = self._mpi_split()
        comm.send(metadata_part, dest=dest_rank)
        comm.Send([array_part, MPIFloat], dest=dest_rank)


    def mpi_send_lambda(self, comm):
        """See parallel.py."""
        return lambda dest_rank: self.mpi_send(comm, dest_rank)


    @staticmethod 
    def mpi_recv(comm, send_rank):

        metadata_part = comm.recv(source=send_rank)

        array_part = np.empty(metadata_part.shape, dtype=NumpyFloat)
        comm.Recv([array_part, MPIFloat], source=send_rank)

        metadata_part.array = array_part

        return metadata_part


    @staticmethod 
    def mpi_recv_lambda(comm):
        """See parallel.py."""
        return lambda send_rank: Container.mpi_recv(comm, send_rank)


    # ================================================================
    # Array indexing methods.

    def get_frame(self, globalID):
        try:
            localID = self.localIDs[globalID]
        except KeyError:
            raise KeyError("Frame with globalID '{0}' not found in container.".format(globalID))
            
        return np.array(self.array[localID], dtype=NumpyFloat)


    def get_frame_pointer(self, globalID):
        try:
            localID = self.localIDs[globalID]
        except KeyError:
            raise KeyError("Frame with globalID '{0}' not found in container.".format(globalID))
            
        return self.array[localID:].ctypes.data_as(ctypes.POINTER(gp_grompy.c_real))


    def get_first_frame_pointer(self):
        try:
            ptr = self.array[0:].ctypes.data_as(ctypes.POINTER(gp_grompy.c_real))
        except KeyError:
            raise KeyError("The container holds no frames.")

        return ptr


    # ================================================================
    # Metadata accessor methods.

    def get_globalIDs_iter(self):
        return iter(self.globalIDs)

    def get_globalIDs(self):
        return list(self.globalIDs)

    def get_localIDs(self):
        return dict(self.localIDs)

    def get_number_frames(self):
        return self.number_frames

    def get_number_atoms(self):
        return self.number_atoms


